{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS8eW5E5B-ld"
      },
      "source": [
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n",
        "!unzip Flickr8k_Dataset.zip\n",
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\n",
        "!unzip Flickr8k_text.zip\n",
        "!wget https://github.com/uclnlp/inferbeddings/raw/master/data/glove/glove.6B.50d.txt.gz\n",
        "!gunzip glove.6B.50d.txt.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9VXhMKXJe4p",
        "outputId": "03537596-a935-4bc8-e160-2e0be9cbea12"
      },
      "source": [
        "!pip install opencv-contrib-python"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alRz8GcsFxnC"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMRhP3V9IAlA"
      },
      "source": [
        "dataset_path = \"/content/Flicker8k_Dataset\"\n",
        "files = os.listdir(dataset_path)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwXMk-kNI-LI"
      },
      "source": [
        "Flicker8k dataset has **8091** images. We will resize all to **224x224** pixels before start."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3Rhs9mYH6Xl"
      },
      "source": [
        "images = []\n",
        "names = []\n",
        "\n",
        "for file in files:\n",
        "    image = cv2.imread(dataset_path + \"/\" + file)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (224,224))\n",
        "    images.append(image)\n",
        "    names.append(file)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eErLnGy3Ivjn"
      },
      "source": [
        "df = pd.read_csv(\"/content/sentences.csv\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zkA8kmAKs0i"
      },
      "source": [
        "def preprocess(sentence):\n",
        "    pattern = r'[^a-zA-z0-9\\s]'\n",
        "    sentence = re.sub(pattern,'',sentence)\n",
        "    words = sentence.split()\n",
        "\n",
        "    words_sm = [word.lower() for word in words]\n",
        "    words_la = [word for word in words_sm if len(word) > 1]\n",
        "    words_f = [word for word in words_la if word.isalpha()]\n",
        "\n",
        "    result_sentence = \"\"\n",
        "    for word in words_f:\n",
        "        result_sentence = result_sentence + word + \" \"\n",
        "\n",
        "    return result_sentence"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX--fRpZKm5g"
      },
      "source": [
        "df['description'] = df['description'].apply(preprocess)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvKyKyDRLOTe"
      },
      "source": [
        "Creating a **dictionary** with key file name and values with image and descriptions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlvJIniwK-LP"
      },
      "source": [
        "mapping = {}\n",
        "idx = 0\n",
        "while idx < len(df):\n",
        "  if df.iloc[idx]['image'] in mapping.keys():\n",
        "      mapping[df.iloc[idx]['image']]['desc'].append(df.iloc[idx]['description'])\n",
        "  else:\n",
        "      mapping[df.iloc[idx]['image']] = {}\n",
        "      mapping[df.iloc[idx]['image']]['desc'] = [df.iloc[idx]['description']]\n",
        "  idx+=1"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga664E2sLae9"
      },
      "source": [
        "keys = [key for key in mapping.keys()]\n",
        "for key in keys:\n",
        "    try:\n",
        "        ind = names.index(key)\n",
        "        mapping[key]['image'] = images[ind]\n",
        "    except:\n",
        "        mapping.pop(key,None)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZCUHDAiMb_9"
      },
      "source": [
        "input_images = []\n",
        "input_descs = []\n",
        "for key in mapping.keys():\n",
        "    input_images.append(mapping[key]['image'])\n",
        "    input_descs.append(mapping[key]['desc'])"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR7cp4c5NeD-"
      },
      "source": [
        "Creating frequency **dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRN91ZJ-NdIB"
      },
      "source": [
        "word_map = {}\n",
        "word_idx = 0\n",
        "for description in input_descs:\n",
        "    for sentence in description:\n",
        "        words = sentence.split()\n",
        "        for word in words:\n",
        "            if word in word_map.keys():\n",
        "                word_map[word]['freq'] = word_map[word]['freq'] + 1\n",
        "            else:\n",
        "                word_map[word] = {}\n",
        "                word_map[word]['idx'] = word_idx\n",
        "                word_map[word]['freq'] = 1\n",
        "                word_idx += 1"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2rchJAgOG7d"
      },
      "source": [
        "out_file = open(\"/content/word_freq.json\", \"w\")\n",
        "json.dump(word_map,out_file)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OisGqJNgOZQ9"
      },
      "source": [
        "new_input_descs = []\n",
        "for description in input_descs:\n",
        "    new_description = []\n",
        "    for sentence in description:\n",
        "        words = sentence.split()\n",
        "        new_words = []\n",
        "        for word in words:\n",
        "            new_words.append(word_map[word]['idx'])\n",
        "        new_description.append(new_words)\n",
        "    new_input_descs.append(new_description)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuSFp9DlQO4U"
      },
      "source": [
        "Train and test data split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J5btidUPCm0"
      },
      "source": [
        "#input_images, new_input_descs\n",
        "#train 80%, test 20%\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(input_images, new_input_descs, test_size = 0.2)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSW9YG2UZqBS"
      },
      "source": [
        "Import **Tensorflow** NN layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G3Kx8u5Zors"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding,Dense, Activation, MaxPool1D,Input, LSTM, Dropout, Input,Activation,add,MaxPooling2D,Conv2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm5MgzQsQmAi"
      },
      "source": [
        "Creating embedding matrix for the word vectors. For embedding I have used **Glove6B** by the standford NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SMaUukOQdtK"
      },
      "source": [
        "embedding_dim = 50\n",
        "vocab_length = len(word_map) + 1\n",
        "embedding_mat = np.zeros((vocab_length, embedding_dim))"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SywsZoZNQzCr"
      },
      "source": [
        "with open('/content/glove.6B.50d.txt') as g_file:\n",
        "    for line in g_file:\n",
        "        word, *embedding = line.split()\n",
        "        if word in word_map.keys():\n",
        "            embedding_mat[word_map[word]['idx']] = np.array(embedding, dtype=\"float32\")[:embedding_dim]"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMsJR3FLZX4U"
      },
      "source": [
        "def Convolution(input_tensor,filters):\n",
        "    x = Conv2D(filters = filters, kernel_size = (3, 3), padding = 'same',strides = (1, 1),\n",
        "                kernel_regularizer = l2(0.003))(input_tensor)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x= Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def create_model(input_shape, vocab_length, embedding_mat, embedding_dim):\n",
        "    inputs_images = Input((input_shape))\n",
        "    conv_1 = Convolution(inputs_images, 32)\n",
        "    maxp_1 = MaxPooling2D(pool_size = (2,2))(conv_1)\n",
        "    conv_2 = Convolution(maxp_1, 64)\n",
        "    maxp_2 = MaxPooling2D(pool_size = (2, 2))(conv_2)\n",
        "    #conv_3 = Convolution(maxp_2, 128)\n",
        "    #maxp_3 = MaxPooling2D(pool_size = (2, 2))(conv_3)\n",
        "    flatten = Flatten()(maxp_2)\n",
        "    dense_1 = Dense(128, activation = 'relu')(flatten) \n",
        "\n",
        "    #NOTE: dense_1 size should be equal to lstm1 size\n",
        "\n",
        "    inputs_language = Input(shape = (25,)) #final length\n",
        "    emb1 = Embedding(input_dim = vocab_length, output_dim = embedding_dim, weights = [embedding_mat], trainable = False)(inputs_language)\n",
        "    dr1 = Dropout(0.2)(emb1)\n",
        "    lstm1 = LSTM(128, return_sequences = True)(dr1)\n",
        "    #dr2 = Dropout(0.2)(lstm1)\n",
        "    #lstm2 = LSTM(256,return_sequences=True)(dr2)\n",
        "\n",
        "    out_1 = add([dense_1, lstm1])\n",
        "    out_2 = Dense(256, activation = 'relu')(out_1)\n",
        "    output = Dense(vocab_length, activation = 'softmax')(out_2)\n",
        "\n",
        "    model = Model(inputs = [inputs_images, inputs_language], outputs = [output])\n",
        "    \n",
        "    #need update of loss function to \n",
        "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"Adam\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30YPeQAJQ0TC"
      },
      "source": [
        "model = create_model((224, 224, 3), vocab_length, embedding_mat, embedding_dim)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyMEi-aPdBgR",
        "outputId": "1ff438da-47ee-46a1-8bef-e401120ba347"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_28 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 224, 224, 32) 896         input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 224, 224, 32) 0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 224, 224, 32) 0           dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling2D) (None, 112, 112, 32) 0           activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 112, 112, 64) 18496       max_pooling2d_30[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 112, 112, 64) 0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 112, 112, 64) 0           dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "input_29 (InputLayer)           [(None, 25)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling2D) (None, 56, 56, 64)   0           activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "embedding_12 (Embedding)        (None, 25, 50)       469300      input_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_14 (Flatten)            (None, 200704)       0           max_pooling2d_31[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 25, 50)       0           embedding_12[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 128)          25690240    flatten_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_13 (LSTM)                  (None, 25, 128)      91648       dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 25, 128)      0           dense_16[0][0]                   \n",
            "                                                                 lstm_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 25, 256)      33024       add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 25, 9386)     2412202     dense_17[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 28,715,806\n",
            "Trainable params: 28,246,506\n",
            "Non-trainable params: 469,300\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHnPYu9AaUU7"
      },
      "source": [
        "#Plot model architecture\n",
        "plot_model(model, to_file = '/content/model_plot.png', show_shapes = True, show_layer_names = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF4HUAomdEdF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}